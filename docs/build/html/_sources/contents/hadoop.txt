Hadoop setup
============

Halvade runs on the Hadoop MapReduce framework, if Hadoop MapReduce version 2.0 or newer is already installed on your cluster, you can continue to the Hadoop configuration section to make sure the advised configuration is set. 

Single node
-----------

Docker
------


Multi node
----------


Hadoop configuration
--------------------

After Hadoop is installed, the configuration needs to be updated to run Halvade in an optimal environment. In Halvade each tasks processes a portion of the input data, however the execution time can vary to a certain degree. For this the task timeout needs to be set high enough, in *mapred-site.xml* change this property to 30 minutes:

.. code-block:: xml
	:linenos:

	<property>
	  <name>mapreduce.task.timeout</name>
	  <value>1800000</value>
	</property>

Next, CDH 5 needs to know how many cores and how much memory is available on the nodes, this is set in *yarn-site.xml*. This is very important for the number of tasks that will be started on the cluster. In this example nodes with 128 GBytes of memory and a dual socket cpu setup with in total 24 cores is used. Because many tools benefit from the hyperthreading capabilities of a cpu, the vcores is set to 48:

.. code-block:: xml
	:linenos:

	<property>
	  <name>yarn.nodemanager.resource.memory-mb</name>
	  <value>131072</value>
	</property>
	<property>
	  <name>yarn.nodemanager.resource.cpu-vcores</name>
	  <value>48</value>
	</property>
	<property>
	  <name>yarn.scheduler.maximum-allocation-mb</name>
	  <value>131072</value>
	</property>
	<property>
	  <name>yarn.scheduler.minimum-allocation-mb</name>
	  <value>512</value>
	</property>
	<property>
	  <name>yarn.scheduler.maximum-allocation-vcores</name>
	  <value>48</value>
	</property>
	<property>
	  <name>yarn.scheduler.minimum-allocation-vcores</name>
	  <value>1</value>
	</property>

After this the configuration needs to be pushed to all nodes:

    $ scp *-site.xml myuser@myCDHnode-<n>.mycompany.com:/etc/hadoop/conf.my_cluster/

And the MapReduce service needs to be restarted:

On the Resource Manager:

    $ sudo service hadoop-yarn-resourcemanager restart

On each NodeManager:

    $ sudo service hadoop-yarn-nodemanager restart

On the JobHistory server:

    $ sudo service hadoop-mapreduce-historyserver restart

